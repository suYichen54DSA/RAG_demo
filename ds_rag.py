# ds_rag.py

import os
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.chains import RetrievalQA

# 1. ç¯å¢ƒ & æ¨¡å‹åˆå§‹åŒ–
API_KEY = "your-api"
BASE_URL = "https://your/url/v1"

# BASE_URL = "https://openrouter.ai/api/v1"

LLM = ChatOpenAI(
    model="deepseek/deepseek-r1-0528:free",
    api_key=API_KEY,
    base_url=BASE_URL,
    temperature=0.0,
)

# 2. åŠ è½½æ–‡æ¡£
loader = DirectoryLoader(
    "rag_word/",  # ä½ æ”¾ .txt æ–‡æ¡£çš„ç›®å½•
    glob="**/*.txt",
    loader_cls=lambda path: TextLoader(path, encoding='utf-8')  # æŒ‡å®š UTF-8 ç¼–ç 
)
docs = loader.load()

# 3. åˆ‡åˆ†æ–‡æ¡£ç‰‡æ®µ
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = splitter.split_documents(docs)
print("ğŸ“„ æ–‡æ¡£åˆ‡ç‰‡æ•°:", len(splits))
if splits:
    print("ç¤ºä¾‹ç‰‡æ®µå†…å®¹ï¼š\n", splits[0].page_content)
input("âœ… æ–‡æ¡£åˆ‡ç‰‡å®Œæˆï¼ŒæŒ‰å›è½¦ç»§ç»­")

# 4. æ„å»ºå‘é‡æ•°æ®åº“ï¼ˆä½¿ç”¨æœ¬åœ° HuggingFace Embeddingï¼‰
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
vectorstore = FAISS.from_documents(splits, embeddings)
print("âœ… FAISS å‘é‡åº“æ„å»ºå®Œæˆ")
input("æŒ‰å›è½¦ç»§ç»­")

# 5. æ„å»º RAG æ£€ç´¢é“¾
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
rag_chain = RetrievalQA.from_chain_type(
    llm=LLM,
    chain_type="stuff",  # ç®€å•æ‹¼æ¥æ£€ç´¢åˆ°çš„ç‰‡æ®µ
    retriever=retriever,
    return_source_documents=True,
)

# 6. æ¯”è¾ƒï¼šç›´æ¥ LLM vs RAG
question = "ä¸­å›½æœ€è‘—åçš„åŸå¸‚æœ‰å“ªäº›ï¼Œä¸¾äº”ä¸ªï¼Ÿä¸ç”¨å…·ä½“ä»‹ç»"

# 6a. åŸå§‹ LLM å›ç­”
baseline_response = LLM.invoke([
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ¸Šåšçš„ä¸­æ–‡åŠ©æ‰‹"},
    {"role": "user", "content": question},
])
print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print("âœ¨ Baseline å›ç­”ï¼ˆä¸å¸¦æ£€ç´¢ï¼‰ï¼š")
print(baseline_response.content)
print()

# 6b. RAG æ£€ç´¢å¢å¼ºå›ç­”
rag_result = rag_chain({"query": question})
print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print("ğŸš€ RAG å›ç­”ï¼ˆå¸¦æ–‡æ¡£æ£€ç´¢ï¼‰ï¼š")
print(rag_result["result"])
print()

print("ğŸ“š ä½¿ç”¨åˆ°çš„æ–‡æ¡£ç‰‡æ®µï¼š")
for doc in rag_result["source_documents"]:
    print("--------")
    print(doc.metadata.get("source", ""), ":\n", doc.page_content[:200].replace("\n", " ") + "â€¦")
